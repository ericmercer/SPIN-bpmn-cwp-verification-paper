Functional integration of human cognition and machine reasoning is an industry-wide problem for critical systems where failure risks human safety or health. The vast differences between human and machine performance properties combined with the inherently distributed and asynchronous nature of human-machine integration makes manual design analysis of any such systems difficult at best. This paper details the use of model checking as a means to systematize design analysis in a way that leverages the graphical workflows with which such systems are commonly modeled. The approach formalizes the functional intent of the system as a cognitive work problem (CWP) and then model checks that the workflow models implement the CWP. A CWP is a computationally independent model stating what a system must accomplish. It is translated into a set of linear temporal logic (LTL) properties that together have the same meaning as the CWP. The workflow models for the system are translated into an equivalent Promela model, and the SPIN model checker verifies whether or not the Promela model implements the LTL properties defined by the CWP. The entire process is illustrated in a case study on a remote patient monitoring system to verify that the system serves its medical purpose and preserves patient safety properties.  This formalized model-based design analysis is an important contribution to conventional evaluations and adds to the assurance of safety in critical systems.

\begin{comment}
Remote health-care that integrates human and machine intelligence for patient monitoring is an active area of research. These systems must take extra precautions for safety since the patients are not in the direct supervision of medical providers. This paper details the application of model checking to the Bionous \phware\ remote patient monitoring system to prove it preserves patient safety properties. Patient safety requirements are formalized in a cognitive work problem that is translated to Linear Temporal Logic properties. A cognitive work problem (CWP) is a computationally independent model stating what a system must accomplish. In this example, the system must take action on risk awareness to enhance patient safety, so the CWP defines risk awareness and requisite decisions given the current risk. The \phware\ workflow is translated to Promela to model the asynchronous behaviors of the patient at home, the artificial intelligence in the cloud, and the clinicians. The LTL and Promela models with added behaviors for patient severity are given to the SPIN model checker to prove the system implements the cognitive work problem, meaning it acts appropriately in regards to risk awareness. This result is an important contribution to conventional evaluations and contributes to the assurance of patient safety in remote health IT.
\end{comment}